{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:14:16.902586Z",
     "start_time": "2025-12-05T10:14:06.067718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import jieba\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "8d8efc17dc5efcf4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MyFiles\\Projects\\learn-deep-learning\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "D:\\MyFiles\\Projects\\learn-deep-learning\\.venv\\Lib\\site-packages\\jieba\\__init__.py:44: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  re_han_default = re.compile(\"([\\u4E00-\\u9FD5a-zA-Z0-9+#&\\._%\\-]+)\", re.U)\n",
      "D:\\MyFiles\\Projects\\learn-deep-learning\\.venv\\Lib\\site-packages\\jieba\\__init__.py:46: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  re_skip_default = re.compile(\"(\\r\\n|\\s)\", re.U)\n",
      "D:\\MyFiles\\Projects\\learn-deep-learning\\.venv\\Lib\\site-packages\\jieba\\finalseg\\__init__.py:78: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  re_skip = re.compile(\"([a-zA-Z0-9]+(?:\\.\\d+)?%?)\")\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:14:26.899829Z",
     "start_time": "2025-12-05T10:14:26.864574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================== 1. 配置参数 =====================\n",
    "class Config:\n",
    "    bert_path = 'bert-base-chinese'  # 预训练BERT路径（自动下载）\n",
    "    max_seq_len = 64  # 文本最大长度\n",
    "    batch_size = 32\n",
    "    learning_rate = 1e-5\n",
    "    bert_lr = 1e-6  # BERT微调学习率\n",
    "    num_epochs = 10\n",
    "    weight_decay = 1e-4\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    gender_weight = 1.0  # 性别损失权重\n",
    "    fans_weight = 0.5    # 粉丝数损失权重\n",
    "    location_weight = 1.2# 位置损失权重\n",
    "\n",
    "config = Config()"
   ],
   "id": "4ef0a6f191c099eb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:14:27.330195Z",
     "start_time": "2025-12-05T10:14:27.325491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================== 2. 数据预处理 =====================\n",
    "def load_data(user_path, weibo_path):\n",
    "    \"\"\"加载并关联用户数据和微博数据\"\"\"\n",
    "    # 加载数据\n",
    "    user_df = pd.read_excel(user_path)\n",
    "    weibo_df = pd.read_excel(weibo_path)\n",
    "\n",
    "    # 数据清洗：只保留有微博文本、性别、粉丝数、位置的样本\n",
    "    user_df = user_df[user_df['性别'].isin(['f', 'm'])].copy()\n",
    "    user_df = user_df.dropna(subset=['位置', '粉丝数']).copy()\n",
    "    weibo_df = weibo_df.dropna(subset=['文本内容']).copy()\n",
    "\n",
    "    # 关联数据（一个用户可能有多条微博，取第一条有效微博）\n",
    "    weibo_df = weibo_df.groupby('uid').first().reset_index()  # 每个用户保留一条微博\n",
    "    data_df = pd.merge(weibo_df, user_df, on='uid', how='inner')\n",
    "\n",
    "    # 处理目标变量\n",
    "    # 2.1 性别：f→0，m→1\n",
    "    data_df['gender_label'] = (data_df['性别'] == 'm').astype(int)\n",
    "\n",
    "    # 2.2 粉丝数：对数变换\n",
    "    data_df['fans_label'] = np.log1p(data_df['粉丝数'])  # log(粉丝数+1)\n",
    "\n",
    "    # 2.3 位置：合并细分地区，编码标签\n",
    "    data_df['location_clean'] = data_df['位置'].str.extract(r'([^ ]+)')[0]  # 提取省份/国家\n",
    "    data_df['location_clean'] = data_df['location_clean'].replace(['海外', '其他'], ['海外地区', '其他地区'])\n",
    "    # 过滤低频类别（样本数≥5）\n",
    "    location_counts = data_df['location_clean'].value_counts()\n",
    "    valid_locations = location_counts[location_counts >= 5].index.tolist()\n",
    "    data_df = data_df[data_df['location_clean'].isin(valid_locations)].copy()\n",
    "\n",
    "    # 位置标签编码\n",
    "    label_encoder = LabelEncoder()\n",
    "    data_df['location_label'] = label_encoder.fit_transform(data_df['location_clean'])\n",
    "\n",
    "    return data_df, label_encoder\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"清洗微博文本\"\"\"\n",
    "    text = str(text)\n",
    "    # 去除@用户、话题、URL、特殊符号\n",
    "    text = re.sub(r'@[^ ]+', '', text)\n",
    "    text = re.sub(r'#.*?#', '', text)\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5a-zA-Z0-9\\s]', '', text)\n",
    "    # 分词\n",
    "    words = jieba.lcut(text.strip())\n",
    "    return ' '.join(words)\n"
   ],
   "id": "98094c04672b0f25",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:14:27.612806Z",
     "start_time": "2025-12-05T10:14:27.608405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================== 3. 数据集类 =====================\n",
    "class WeiboDataset(Dataset):\n",
    "    def __init__(self, texts, gender_labels, fans_labels, location_labels, tokenizer, max_seq_len):\n",
    "        self.texts = texts\n",
    "        self.gender_labels = gender_labels\n",
    "        self.fans_labels = fans_labels\n",
    "        self.location_labels = location_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 文本编码\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_seq_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].flatten()\n",
    "        attention_mask = encoding['attention_mask'].flatten()\n",
    "\n",
    "        # 标签转换为tensor\n",
    "        gender = torch.tensor(self.gender_labels[idx], dtype=torch.long)\n",
    "        fans = torch.tensor(self.fans_labels[idx], dtype=torch.float32)\n",
    "        location = torch.tensor(self.location_labels[idx], dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'gender': gender,\n",
    "            'fans': fans,\n",
    "            'location': location\n",
    "        }"
   ],
   "id": "524d5bb661cb9f67",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:14:27.768255Z",
     "start_time": "2025-12-05T10:14:27.764287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================== 4. 多输出模型定义 =====================\n",
    "class MultiOutputBERT(nn.Module):\n",
    "    def __init__(self, bert_path, num_location_classes):\n",
    "        super().__init__()\n",
    "        # 共享BERT编码器\n",
    "        self.bert = BertModel.from_pretrained(bert_path, output_hidden_states=True)\n",
    "        self.bert_hidden_size = self.bert.config.hidden_size\n",
    "\n",
    "        # 冻结BERT前6层（可选，根据数据量调整）\n",
    "        for param in list(self.bert.parameters())[:12]:\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # 性别输出头（二分类）\n",
    "        self.gender_head = nn.Sequential(\n",
    "            nn.Linear(self.bert_hidden_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "        # 粉丝数输出头（回归）\n",
    "        self.fans_head = nn.Sequential(\n",
    "            nn.Linear(self.bert_hidden_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "        # 位置输出头（多分类）\n",
    "        self.location_head = nn.Sequential(\n",
    "            nn.Linear(self.bert_hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_location_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # BERT编码：取[CLS] token的输出\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # (batch_size, hidden_size)\n",
    "\n",
    "        # 三个任务输出\n",
    "        gender_logits = self.gender_head(cls_embedding)\n",
    "        fans_pred = self.fans_head(cls_embedding).squeeze(-1)  # (batch_size,)\n",
    "        location_logits = self.location_head(cls_embedding)\n",
    "\n",
    "        return gender_logits, fans_pred, location_logits\n"
   ],
   "id": "6d989ecb72da3e64",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:14:27.911585Z",
     "start_time": "2025-12-05T10:14:27.904973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================== 5. 训练与评估函数 =====================\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion_gender, criterion_fans, criterion_location, config):\n",
    "    model.to(config.device)\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(config.num_epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            # 数据移到设备\n",
    "            input_ids = batch['input_ids'].to(config.device)\n",
    "            attention_mask = batch['attention_mask'].to(config.device)\n",
    "            gender_labels = batch['gender'].to(config.device)\n",
    "            fans_labels = batch['fans'].to(config.device)\n",
    "            location_labels = batch['location'].to(config.device)\n",
    "\n",
    "            # 前向传播\n",
    "            optimizer.zero_grad()\n",
    "            gender_logits, fans_pred, location_logits = model(input_ids, attention_mask)\n",
    "\n",
    "            # 计算损失\n",
    "            loss_gender = criterion_gender(gender_logits, gender_labels)\n",
    "            loss_fans = criterion_fans(fans_pred, fans_labels)\n",
    "            loss_location = criterion_location(location_logits, location_labels)\n",
    "            total_loss = (config.gender_weight * loss_gender +\n",
    "                          config.fans_weight * loss_fans +\n",
    "                          config.location_weight * loss_location)\n",
    "\n",
    "            # 反向传播\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += total_loss.item() * input_ids.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # 验证阶段\n",
    "        val_metrics = evaluate_model(model, val_loader, criterion_gender, criterion_fans, criterion_location, config)\n",
    "        val_loss = val_metrics['total_loss']\n",
    "\n",
    "        # 保存最优模型\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'multi_output_bert_best.pth')\n",
    "            print(f'Epoch {epoch+1} | 最优模型保存，验证总损失：{val_loss:.4f}')\n",
    "\n",
    "        # 打印日志\n",
    "        print(f'''Epoch {epoch+1}/{config.num_epochs}\n",
    "        训练总损失：{train_loss:.4f}\n",
    "        验证总损失：{val_loss:.4f}\n",
    "        性别准确率：{val_metrics['gender_acc']:.4f} | 性别F1：{val_metrics['gender_f1']:.4f}\n",
    "        粉丝数RMSE：{val_metrics['fans_rmse']:.4f} | 粉丝数R²：{val_metrics['fans_r2']:.4f}\n",
    "        位置准确率：{val_metrics['location_acc']:.4f}''')\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion_gender, criterion_fans, criterion_location, config):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # 存储预测结果和真实标签\n",
    "    gender_preds, gender_trues = [], []\n",
    "    fans_preds, fans_trues = [], []\n",
    "    location_preds, location_trues = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(config.device)\n",
    "            attention_mask = batch['attention_mask'].to(config.device)\n",
    "            gender_labels = batch['gender'].to(config.device)\n",
    "            fans_labels = batch['fans'].to(config.device)\n",
    "            location_labels = batch['location'].to(config.device)\n",
    "\n",
    "            # 前向传播\n",
    "            gender_logits, fans_pred, location_logits = model(input_ids, attention_mask)\n",
    "\n",
    "            # 计算损失\n",
    "            loss_gender = criterion_gender(gender_logits, gender_labels)\n",
    "            loss_fans = criterion_fans(fans_pred, fans_labels)\n",
    "            loss_location = criterion_location(location_logits, location_labels)\n",
    "            batch_loss = (config.gender_weight * loss_gender +\n",
    "                          config.fans_weight * loss_fans +\n",
    "                          config.location_weight * loss_location)\n",
    "            total_loss += batch_loss.item() * input_ids.size(0)\n",
    "\n",
    "            # 收集预测结果（还原对数变换）\n",
    "            gender_pred = torch.argmax(gender_logits, dim=1).cpu().numpy()\n",
    "            location_pred = torch.argmax(location_logits, dim=1).cpu().numpy()\n",
    "\n",
    "            gender_preds.extend(gender_pred)\n",
    "            gender_trues.extend(gender_labels.cpu().numpy())\n",
    "            fans_preds.extend(np.expm1(fans_pred.cpu().numpy()))  # 还原：exp(x)-1\n",
    "            fans_trues.extend(np.expm1(fans_labels.cpu().numpy()))\n",
    "            location_preds.extend(location_pred)\n",
    "            location_trues.extend(location_labels.cpu().numpy())\n",
    "\n",
    "    # 计算评估指标\n",
    "    total_loss /= len(dataloader.dataset)\n",
    "    gender_acc = accuracy_score(gender_trues, gender_preds)\n",
    "    gender_f1 = f1_score(gender_trues, gender_preds, average='binary')\n",
    "    fans_rmse = np.sqrt(mean_squared_error(fans_trues, fans_preds))\n",
    "    fans_r2 = r2_score(fans_trues, fans_preds)\n",
    "    location_acc = accuracy_score(location_trues, location_preds)\n",
    "\n",
    "    return {\n",
    "        'total_loss': total_loss,\n",
    "        'gender_acc': gender_acc,\n",
    "        'gender_f1': gender_f1,\n",
    "        'fans_rmse': fans_rmse,\n",
    "        'fans_r2': fans_r2,\n",
    "        'location_acc': location_acc\n",
    "    }\n"
   ],
   "id": "2b2d0b56d221ef22",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:14:28.409286Z",
     "start_time": "2025-12-05T10:14:28.405413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===================== 6. 推理函数 =====================\n",
    "def infer(model, tokenizer, text, label_encoder, config):\n",
    "    \"\"\"单条微博文本推理\"\"\"\n",
    "    model.eval()\n",
    "    # 文本预处理和编码\n",
    "    clean_txt = clean_text(text)\n",
    "    encoding = tokenizer(\n",
    "        clean_txt,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=config.max_seq_len,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encoding['input_ids'].to(config.device)\n",
    "    attention_mask = encoding['attention_mask'].to(config.device)\n",
    "\n",
    "    # 推理\n",
    "    with torch.no_grad():\n",
    "        gender_logits, fans_pred, location_logits = model(input_ids, attention_mask)\n",
    "\n",
    "    # 结果解析\n",
    "    gender_prob = torch.softmax(gender_logits, dim=1).cpu().numpy()[0]\n",
    "    gender = '男性' if gender_prob[1] > 0.5 else '女性'\n",
    "    gender_confidence = max(gender_prob)\n",
    "\n",
    "    fans = int(np.expm1(fans_pred.cpu().numpy()[0]))  # 还原真实粉丝数\n",
    "\n",
    "    location_prob = torch.softmax(location_logits, dim=1).cpu().numpy()[0]\n",
    "    location_idx = np.argmax(location_prob)\n",
    "    location = label_encoder.inverse_transform([location_idx])[0]\n",
    "    location_confidence = location_prob[location_idx]\n",
    "\n",
    "    return {\n",
    "        '性别': gender,\n",
    "        '性别置信度': f'{gender_confidence:.2f}',\n",
    "        '预测粉丝数': fans,\n",
    "        '位置': location,\n",
    "        '位置置信度': f'{location_confidence:.2f}'\n",
    "    }\n"
   ],
   "id": "8cd85f9a99a2450f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T10:16:36.096728Z",
     "start_time": "2025-12-05T10:15:37.698337Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# ===================== 7. 主函数（执行流程） =====================\n",
    "if __name__ == '__main__':\n",
    "    # 1. 加载和预处理数据\n",
    "    user_path = r'datasets/Weibo/用户信息.xlsx'  # 替换为你的用户数据路径\n",
    "    weibo_path = r'datasets/Weibo/用户微博总.xlsx'  # 替换为你的微博数据路径\n",
    "    data_df, label_encoder = load_data(user_path, weibo_path)\n",
    "\n",
    "    # 清洗文本\n",
    "    data_df['clean_text'] = data_df['文本内容'].apply(clean_text)\n",
    "\n",
    "    # 划分数据集（按用户ID划分，避免数据泄露）\n",
    "    train_df, val_df = train_test_split(data_df, test_size=0.2, random_state=42, stratify=data_df['gender_label'])\n",
    "\n",
    "    # 2. 初始化Tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained(config.bert_path)\n",
    "\n",
    "    # 3. 创建数据集和DataLoader\n",
    "    train_dataset = WeiboDataset(\n",
    "        texts=train_df['clean_text'].tolist(),\n",
    "        gender_labels=train_df['gender_label'].tolist(),\n",
    "        fans_labels=train_df['fans_label'].tolist(),\n",
    "        location_labels=train_df['location_label'].tolist(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_len=config.max_seq_len\n",
    "    )\n",
    "    val_dataset = WeiboDataset(\n",
    "        texts=val_df['clean_text'].tolist(),\n",
    "        gender_labels=val_df['gender_label'].tolist(),\n",
    "        fans_labels=val_df['fans_label'].tolist(),\n",
    "        location_labels=val_df['location_label'].tolist(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_len=config.max_seq_len\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "    # 4. 初始化模型和损失函数\n",
    "    num_location_classes = len(label_encoder.classes_)\n",
    "    model = MultiOutputBERT(config.bert_path, num_location_classes)\n",
    "\n",
    "    # 损失函数\n",
    "    criterion_gender = nn.CrossEntropyLoss()\n",
    "    criterion_fans = nn.MSELoss()\n",
    "    criterion_location = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 优化器（分层学习率）\n",
    "    param_groups = [\n",
    "        {'params': model.bert.parameters(), 'lr': config.bert_lr},\n",
    "        {'params': model.gender_head.parameters(), 'lr': config.learning_rate},\n",
    "        {'params': model.fans_head.parameters(), 'lr': config.learning_rate},\n",
    "        {'params': model.location_head.parameters(), 'lr': config.learning_rate}\n",
    "    ]\n",
    "    optimizer = optim.AdamW(param_groups, weight_decay=config.weight_decay)\n",
    "\n",
    "    # 5. 训练模型\n",
    "    print(f'开始训练，设备：{config.device}')\n",
    "    train_model(model, train_loader, val_loader, optimizer, criterion_gender, criterion_fans, criterion_location, config)\n",
    "\n",
    "    # 6. 加载最优模型进行推理\n",
    "    model.load_state_dict(torch.load('multi_output_bert_best.pth'))\n",
    "    model.to(config.device)\n",
    "\n",
    "    # 测试推理\n",
    "    test_text = '今天去故宫玩了，人好多呀，风景超美～'  # 测试文本\n",
    "    result = infer(model, tokenizer, test_text, label_encoder, config)\n",
    "    print('\\n推理结果：')\n",
    "    for k, v in result.items():\n",
    "        print(f'{k}：{v}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练，设备：cuda\n",
      "Epoch 1 | 最优模型保存，验证总损失：24.3285\n",
      "Epoch 1/10\n",
      "        训练总损失：25.2852\n",
      "        验证总损失：24.3285\n",
      "        性别准确率：0.6860 | 性别F1：0.2895\n",
      "        粉丝数RMSE：1817967.1433 | 粉丝数R²：-0.0224\n",
      "        位置准确率：0.0349\n",
      "Epoch 2 | 最优模型保存，验证总损失：21.8934\n",
      "Epoch 2/10\n",
      "        训练总损失：23.0303\n",
      "        验证总损失：21.8934\n",
      "        性别准确率：0.6977 | 性别F1：0.0000\n",
      "        粉丝数RMSE：1817966.9954 | 粉丝数R²：-0.0224\n",
      "        位置准确率：0.0407\n",
      "Epoch 3 | 最优模型保存，验证总损失：19.3802\n",
      "Epoch 3/10\n",
      "        训练总损失：20.7798\n",
      "        验证总损失：19.3802\n",
      "        性别准确率：0.6977 | 性别F1：0.0000\n",
      "        粉丝数RMSE：1817966.6986 | 粉丝数R²：-0.0224\n",
      "        位置准确率：0.1628\n",
      "Epoch 4 | 最优模型保存，验证总损失：16.8683\n",
      "Epoch 4/10\n",
      "        训练总损失：18.4368\n",
      "        验证总损失：16.8683\n",
      "        性别准确率：0.6977 | 性别F1：0.0000\n",
      "        粉丝数RMSE：1817966.0899 | 粉丝数R²：-0.0224\n",
      "        位置准确率：0.2035\n",
      "Epoch 5 | 最优模型保存，验证总损失：14.5154\n",
      "Epoch 5/10\n",
      "        训练总损失：16.1821\n",
      "        验证总损失：14.5154\n",
      "        性别准确率：0.6977 | 性别F1：0.0000\n",
      "        粉丝数RMSE：1817964.7274 | 粉丝数R²：-0.0224\n",
      "        位置准确率：0.2035\n",
      "Epoch 6 | 最优模型保存，验证总损失：12.6225\n",
      "Epoch 6/10\n",
      "        训练总损失：14.2085\n",
      "        验证总损失：12.6225\n",
      "        性别准确率：0.6977 | 性别F1：0.0000\n",
      "        粉丝数RMSE：1817962.0772 | 粉丝数R²：-0.0224\n",
      "        位置准确率：0.2035\n",
      "Epoch 7 | 最优模型保存，验证总损失：11.2748\n",
      "Epoch 7/10\n",
      "        训练总损失：12.7521\n",
      "        验证总损失：11.2748\n",
      "        性别准确率：0.6977 | 性别F1：0.0000\n",
      "        粉丝数RMSE：1817957.6124 | 粉丝数R²：-0.0224\n",
      "        位置准确率：0.2035\n",
      "Epoch 8 | 最优模型保存，验证总损失：10.4401\n",
      "Epoch 8/10\n",
      "        训练总损失：11.6302\n",
      "        验证总损失：10.4401\n",
      "        性别准确率：0.6977 | 性别F1：0.0000\n",
      "        粉丝数RMSE：1817951.4796 | 粉丝数R²：-0.0224\n",
      "        位置准确率：0.2035\n",
      "Epoch 9 | 最优模型保存，验证总损失：9.9193\n",
      "Epoch 9/10\n",
      "        训练总损失：10.8641\n",
      "        验证总损失：9.9193\n",
      "        性别准确率：0.6977 | 性别F1：0.0000\n",
      "        粉丝数RMSE：1817943.7709 | 粉丝数R²：-0.0224\n",
      "        位置准确率：0.2035\n",
      "Epoch 10 | 最优模型保存，验证总损失：9.1694\n",
      "Epoch 10/10\n",
      "        训练总损失：10.4168\n",
      "        验证总损失：9.1694\n",
      "        性别准确率：0.6977 | 性别F1：0.0000\n",
      "        粉丝数RMSE：1817934.8914 | 粉丝数R²：-0.0223\n",
      "        位置准确率：0.2035\n",
      "\n",
      "推理结果：\n",
      "性别：女性\n",
      "性别置信度：0.70\n",
      "预测粉丝数：179\n",
      "位置：其他地区\n",
      "位置置信度：0.21\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
