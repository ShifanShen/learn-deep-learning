{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:46:13.853231Z",
     "start_time": "2025-12-05T10:46:13.850319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from tqdm import tqdm\n"
   ],
   "id": "c3da540f5a42cf3f",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:46:20.039268Z",
     "start_time": "2025-12-05T10:46:20.035599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleTokenizer:\n",
    "    def __init__(self):\n",
    "        self.word2idx = {\"<pad>\":0, \"<bos>\":1, \"<eos>\":2, \"<unk>\":3}\n",
    "        self.idx2word = {0:\"<pad>\", 1:\"<bos>\", 2:\"<eos>\", 3:\"<unk>\"}\n",
    "\n",
    "    def build_vocab(self, sentences, min_freq=1):\n",
    "        freq = {}\n",
    "        for sent in sentences:\n",
    "            for w in sent.split():\n",
    "                freq[w] = freq.get(w,0)+1\n",
    "        for w, c in freq.items():\n",
    "            if c >= min_freq:\n",
    "                idx = len(self.word2idx)\n",
    "                self.word2idx[w] = idx\n",
    "                self.idx2word[idx] = w\n",
    "\n",
    "    def encode(self, sentence):\n",
    "        return [self.word2idx.get(w,3) for w in sentence.split()]\n",
    "\n",
    "    def decode(self, ids):\n",
    "        return \" \".join([self.idx2word[i] for i in ids if i > 2])\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.word2idx)\n"
   ],
   "id": "64d5e5ee282e96c5",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:46:21.192581Z",
     "start_time": "2025-12-05T10:46:21.189070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_parallel_data(zh_file, en_file):\n",
    "    with open(zh_file, encoding=\"utf-8\") as f:\n",
    "        zh = [l.strip() for l in f.readlines()]\n",
    "    with open(en_file, encoding=\"utf-8\") as f:\n",
    "        en = [l.strip() for l in f.readlines()]\n",
    "    assert len(zh) == len(en)\n",
    "    return zh, en\n"
   ],
   "id": "245abebdfc3b1688",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:46:23.768387Z",
     "start_time": "2025-12-05T10:46:23.765470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, zh_list, en_list, zh_tok, en_tok):\n",
    "        self.zh = zh_list\n",
    "        self.en = en_list\n",
    "        self.zh_tok = zh_tok\n",
    "        self.en_tok = en_tok\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_ids = [1] + self.zh_tok.encode(self.zh[idx]) + [2]\n",
    "        tgt_ids = [1] + self.en_tok.encode(self.en[idx]) + [2]\n",
    "        return torch.tensor(src_ids), torch.tensor(tgt_ids)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.zh)\n"
   ],
   "id": "3c4986942ecb725e",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:46:26.730462Z",
     "start_time": "2025-12-05T10:46:26.728233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collate_fn(batch):\n",
    "    src, tgt = zip(*batch)\n",
    "    src = pad_sequence(src, batch_first=True, padding_value=0)\n",
    "    tgt = pad_sequence(tgt, batch_first=True, padding_value=0)\n",
    "    return src, tgt\n"
   ],
   "id": "47409700b887ad44",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:46:30.271114Z",
     "start_time": "2025-12-05T10:46:30.266220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerMT(nn.Module):\n",
    "    def __init__(self, vocab_src, vocab_tgt, d_model=256, nhead=4, num_layers=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.src_embed = nn.Embedding(vocab_src, d_model)\n",
    "        self.tgt_embed = nn.Embedding(vocab_tgt, d_model)\n",
    "        self.pos = PositionalEncoding(d_model)\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(d_model, vocab_tgt)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.pos(self.src_embed(src))\n",
    "        tgt = self.pos(self.tgt_embed(tgt))\n",
    "\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(\n",
    "            tgt.size(1)\n",
    "        ).to(src.device)\n",
    "\n",
    "        out = self.transformer(\n",
    "            src.transpose(0,1),\n",
    "            tgt.transpose(0,1),\n",
    "            tgt_mask=tgt_mask\n",
    "        )\n",
    "\n",
    "        out = out.transpose(0,1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0)/d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div)\n",
    "        pe[:, 1::2] = torch.cos(position * div)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)].to(x.device)\n"
   ],
   "id": "7cfd194806a77cb0",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:46:33.883053Z",
     "start_time": "2025-12-05T10:46:33.879411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, loader, optimizer, criterion, epochs=10):\n",
    "    model.train()\n",
    "    for ep in range(epochs):\n",
    "        total = 0\n",
    "        for src, tgt in tqdm(loader):\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "            tgt_in = tgt[:, :-1]\n",
    "            tgt_out = tgt[:, 1:].reshape(-1)\n",
    "\n",
    "            logits = model(src, tgt_in).reshape(-1, model.fc.out_features)\n",
    "            loss = criterion(logits, tgt_out)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total += loss.item()\n",
    "        print(f\"Epoch {ep+1} Loss = {total/len(loader):.4f}\")\n"
   ],
   "id": "1c6234201e594dbd",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:46:38.903720Z",
     "start_time": "2025-12-05T10:46:38.900843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def translate(model, sentence, zh_tok, en_tok, max_len=40):\n",
    "    model.eval()\n",
    "    src = torch.tensor([[1] + zh_tok.encode(sentence) + [2]]).to(device)\n",
    "\n",
    "    tgt = torch.tensor([[1]]).to(device)\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        logits = model(src, tgt)\n",
    "        next_token = logits[0,-1].argmax().item()\n",
    "        tgt = torch.cat([tgt, torch.tensor([[next_token]]).to(device)], dim=1)\n",
    "        if next_token == 2:\n",
    "            break\n",
    "    return en_tok.decode(tgt[0].tolist())\n"
   ],
   "id": "da9a0a195ca874ec",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:46:54.987665Z",
     "start_time": "2025-12-05T10:46:54.983520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "zh_sentences = [\n",
    "    \"我 爱 学习 人工智能\",\n",
    "    \"今天天气 很 好\",\n",
    "    \"我 喜欢 看 电影\",\n",
    "    \"你 在 做 什么\",\n",
    "    \"我们 明天 去 北京\",\n",
    "    \"这是 一个 很 好 的 想法\",\n",
    "    \"请问 洗手间 在 哪里\",\n",
    "    \"我 在 找 工作\",\n",
    "    \"他 是 一名 工程师\",\n",
    "    \"她 喜欢 吃 苹果\",\n",
    "]\n",
    "\n",
    "en_sentences = [\n",
    "    \"I love studying artificial intelligence\",\n",
    "    \"The weather is very good today\",\n",
    "    \"I like watching movies\",\n",
    "    \"What are you doing\",\n",
    "    \"We will go to Beijing tomorrow\",\n",
    "    \"This is a very good idea\",\n",
    "    \"Excuse me where is the restroom\",\n",
    "    \"I am looking for a job\",\n",
    "    \"He is an engineer\",\n",
    "    \"She likes eating apples\",\n",
    "]\n",
    "\n",
    "# 扩展成 500 条\n",
    "ZH = []\n",
    "EN = []\n",
    "for i in range(50):\n",
    "    for z, e in zip(zh_sentences, en_sentences):\n",
    "        ZH.append(z)\n",
    "        EN.append(e)\n",
    "\n",
    "# 写入文件\n",
    "with open(\"train.zh\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in ZH:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "with open(\"train.en\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in EN:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(\"训练数据 train.zh / train.en 已成功生成，共\", len(ZH), \"行\")\n"
   ],
   "id": "86b7bd49ceb642c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据 train.zh / train.en 已成功生成，共 500 行\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T10:47:11.251404Z",
     "start_time": "2025-12-05T10:47:06.935291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ① 加载数据\n",
    "zh, en = load_parallel_data(\"train.zh\", \"train.en\")\n",
    "\n",
    "# ② 构建词表\n",
    "zh_tok = SimpleTokenizer()\n",
    "en_tok = SimpleTokenizer()\n",
    "zh_tok.build_vocab(zh)\n",
    "en_tok.build_vocab(en)\n",
    "\n",
    "# ③ 构建 Dataset & Loader\n",
    "ds = TranslationDataset(zh, en, zh_tok, en_tok)\n",
    "loader = DataLoader(ds, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# ④ 初始化模型\n",
    "model = TransformerMT(\n",
    "    vocab_src=zh_tok.vocab_size,\n",
    "    vocab_tgt=en_tok.vocab_size,\n",
    "    d_model=256,\n",
    "    nhead=4,\n",
    "    num_layers=4\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "\n",
    "# ⑤ 训练\n",
    "train_model(model, loader, optimizer, criterion, epochs=10)\n",
    "\n",
    "# ⑥ 测试翻译\n",
    "print(translate(model, \"我 喜欢 学习 人工智能\", zh_tok, en_tok))\n"
   ],
   "id": "7a4f68003537298",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MyFiles\\Projects\\learn-deep-learning\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "100%|██████████| 16/16 [00:00<00:00, 41.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss = 2.6941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 35.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss = 0.4069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 38.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss = 0.0716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 35.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss = 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 36.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss = 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 43.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss = 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 40.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss = 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 34.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss = 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 35.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss = 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 43.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss = 0.0086\n",
      "I love studying artificial intelligence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
