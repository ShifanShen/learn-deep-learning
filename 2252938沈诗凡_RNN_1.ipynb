{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T08:33:04.692513Z",
     "start_time": "2025-11-29T08:33:04.689476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\"\"\"\n",
    "任务 1：多特征方式的电影评论分类\n",
    "    1. one-hot + MLP\n",
    "    2. TF-IDF + LogisticRegression\n",
    "    3. Embedding + LSTM（可调 maxlen / embed_dim）\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "6a9e68ba07d651d9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T08:36:01.114553Z",
     "start_time": "2025-11-29T08:35:58.585720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===========================\n",
    "# 参数\n",
    "# ===========================\n",
    "vocab_size = 20000\n",
    "maxlen_list = [100, 200]\n",
    "embed_dim_list = [64, 128]\n",
    "batch_size = 64\n",
    "epochs = 3\n",
    "\n",
    "# ===========================\n",
    "# 加载 Keras IMDB\n",
    "# ===========================\n",
    "print(\"Loading IMDB...\")\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "\n",
    "train_text = [\" \".join(map(str, seq)) for seq in x_train]\n",
    "test_text  = [\" \".join(map(str, seq)) for seq in x_test]\n"
   ],
   "id": "eb623f3c15bb110",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IMDB...\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T08:36:04.111937Z",
     "start_time": "2025-11-29T08:36:04.109284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===========================\n",
    "# 1. TF-IDF + Logistic Regression\n",
    "# ===========================\n",
    "def tfidf_classification():\n",
    "    print(\"\\n=== TF-IDF + Logistic Regression ===\")\n",
    "    vectorizer = TfidfVectorizer(max_features=20000)\n",
    "    X_train = vectorizer.fit_transform(train_text)\n",
    "    X_test = vectorizer.transform(test_text)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"TF-IDF Accuracy:\", accuracy_score(y_test, y_pred))"
   ],
   "id": "41e9a4991ea250da",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T08:36:04.610999Z",
     "start_time": "2025-11-29T08:36:04.606337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===========================\n",
    "# 2. One-hot + MLP\n",
    "# ===========================\n",
    "def one_hot_mlp():\n",
    "    print(\"\\n=== One-hot + MLP ===\")\n",
    "    # 多热编码\n",
    "    X_train = np.zeros((len(x_train), vocab_size))\n",
    "    X_test = np.zeros((len(x_test), vocab_size))\n",
    "\n",
    "    for i, seq in enumerate(x_train):\n",
    "        X_train[i, seq] = 1\n",
    "    for i, seq in enumerate(x_test):\n",
    "        X_test[i, seq] = 1\n",
    "\n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "    y_train_t = torch.FloatTensor(y_train)\n",
    "    X_test = torch.FloatTensor(X_test)\n",
    "    y_test_t = torch.FloatTensor(y_test)\n",
    "\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(vocab_size, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.fc(x)\n",
    "\n",
    "    model = MLP().to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_train, y_train_t)\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    for epoch in range(2):  # one-hot 很慢，所以只训练 2 epoch\n",
    "        for x_b, y_b in loader:\n",
    "            x_b, y_b = x_b.to(device), y_b.to(device)\n",
    "\n",
    "            pred = model(x_b).squeeze()\n",
    "            loss = criterion(pred, y_b)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss = {loss.item():.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(X_test.to(device)).squeeze()\n",
    "        pred_label = (pred >= 0.5).long().cpu().numpy()\n",
    "\n",
    "    print(\"One-hot MLP Accuracy:\", accuracy_score(y_test, pred_label))"
   ],
   "id": "9d8d4a3fa3484861",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T08:36:05.325691Z",
     "start_time": "2025-11-29T08:36:05.319805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===========================\n",
    "# 3. Embedding + LSTM（可调 maxlen 和 embed_dim）\n",
    "# ===========================\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, (h, c) = self.lstm(x)\n",
    "        h = h[-1]\n",
    "        return self.sigmoid(self.fc(h))\n",
    "\n",
    "def train_lstm(maxlen, embed_dim):\n",
    "    print(f\"\\n=== LSTM (maxlen={maxlen}, embed_dim={embed_dim}) ===\")\n",
    "\n",
    "    X_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "    X_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "    X_train = torch.LongTensor(X_train)\n",
    "    X_test = torch.LongTensor(X_test)\n",
    "    y_train_t = torch.FloatTensor(y_train)\n",
    "    y_test_t = torch.LongTensor(y_test)\n",
    "\n",
    "    loader = DataLoader(torch.utils.data.TensorDataset(X_train, y_train_t),\n",
    "                        batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(torch.utils.data.TensorDataset(X_test, y_test_t),\n",
    "                             batch_size=batch_size)\n",
    "\n",
    "    model = LSTMClassifier(vocab_size, embed_dim).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for x_b, y_b in loader:\n",
    "            x_b, y_b = x_b.to(device), y_b.to(device)\n",
    "            pred = model(x_b).squeeze()\n",
    "            loss = criterion(pred, y_b)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss={total_loss/len(loader):.4f}\")\n",
    "\n",
    "    # 评估\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_b, y_b in test_loader:\n",
    "            x_b, y_b = x_b.to(device), y_b.to(device)\n",
    "            pred = model(x_b).squeeze()\n",
    "            pred_label = (pred >= 0.5).long()\n",
    "            correct += (pred_label == y_b).sum().item()\n",
    "            total += y_b.size(0)\n",
    "\n",
    "    print(f\"LSTM Accuracy = {correct/total:.4f}\")"
   ],
   "id": "52d7deccab33731",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-29T08:36:31.076853Z",
     "start_time": "2025-11-29T08:36:05.927402Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# ===========================\n",
    "# 主程序\n",
    "# ===========================\n",
    "if __name__ == \"__main__\":\n",
    "    tfidf_classification()\n",
    "    one_hot_mlp()\n",
    "\n",
    "    for maxlen in maxlen_list:\n",
    "        for emb in embed_dim_list:\n",
    "            train_lstm(maxlen, emb)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TF-IDF + Logistic Regression ===\n",
      "TF-IDF Accuracy: 0.8884\n",
      "\n",
      "=== One-hot + MLP ===\n",
      "Epoch 1, Loss = 0.1651\n",
      "Epoch 2, Loss = 0.3243\n",
      "One-hot MLP Accuracy: 0.87048\n",
      "\n",
      "=== LSTM (maxlen=100, embed_dim=64) ===\n",
      "Epoch 1, Loss=0.6175\n",
      "Epoch 2, Loss=0.4636\n",
      "Epoch 3, Loss=0.3626\n",
      "LSTM Accuracy = 0.8223\n",
      "\n",
      "=== LSTM (maxlen=100, embed_dim=128) ===\n",
      "Epoch 1, Loss=0.5612\n",
      "Epoch 2, Loss=0.3974\n",
      "Epoch 3, Loss=0.2961\n",
      "LSTM Accuracy = 0.8411\n",
      "\n",
      "=== LSTM (maxlen=200, embed_dim=64) ===\n",
      "Epoch 1, Loss=0.6144\n",
      "Epoch 2, Loss=0.4694\n",
      "Epoch 3, Loss=0.4150\n",
      "LSTM Accuracy = 0.8342\n",
      "\n",
      "=== LSTM (maxlen=200, embed_dim=128) ===\n",
      "Epoch 1, Loss=0.6099\n",
      "Epoch 2, Loss=0.5409\n",
      "Epoch 3, Loss=0.3970\n",
      "LSTM Accuracy = 0.8216\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
